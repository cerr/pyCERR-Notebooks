{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cerr/pycerr-notebooks/blob/main/auto_register_segment_MR_Pancreas_OARs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNoydh-PsgiD"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial, we will demonstrate how to apply a pre-trained AI model [1] for deformable registration and segmentation of organs at risk (OARs) on longitudinal T2w-MRI scans using pyCERR.\n",
    "\n",
    "\n",
    "## Requirements\n",
    "* Python>=3.8\n",
    "* Applying this model requires access to a GPU.  \n",
    "  *On Colab* :  `Runtime > Change runtime type > Select GPU `  \n",
    "  \n",
    "## I/O  \n",
    "\n",
    "* **Inputs**: DICOM-format longitundinal T2w MRI of the pancreas and segmentation masks of the liver, bowels (small, large), and duo-stomach on the baseline scan.\n",
    "\n",
    "* Pre-processing: The earlier scan must be rigidly registered to the later scan, and input segmentations of the OARs listed below must be available on the earlier scan.  \n",
    "\n",
    "* **Outputs**:  \n",
    "  [1] DICOM RTStruct-format segmentations of\n",
    "  * Liver\n",
    "  * Bowel_Lg\n",
    "  * Bowel_Sm\n",
    "  * Duostomach\n",
    "  \n",
    "  [2] Deformable vector field (DVF) to deform the earlier (moving) scan to a later (baseline) scan.      \n",
    "      \n",
    "      \n",
    "  Input data should be organized as: one directory of DICOM images per patient.       \n",
    "    \n",
    "```    \n",
    "    Input dir\n",
    "            |------Pat1  \n",
    "                      |---Week1\n",
    "                            |------REG_img1.dcm  \n",
    "                                   REG_img2.dcm  \n",
    "                                   ....  \n",
    "                                   REG_RTSRTUCT  \n",
    "                      |---Week2\n",
    "                            |------img1.dcm  \n",
    "                                   img2.dcm  \n",
    "                                   ....  \n",
    "                                   ....  \n",
    "            |-----Pat2  \n",
    "                     |---Week1\n",
    "                            |------REG_img1.dcm  \n",
    "                                   REG_img2.dcm  \n",
    "                                   ....  \n",
    "                                   REG_RTSRTUCT  \n",
    "                      |---Week2\n",
    "                            |------img1.dcm  \n",
    "                                   img2.dcm  \n",
    "                                   ....  \n",
    "                                   ....\n",
    "```\n",
    "\n",
    "\n",
    "## Installing the model and its dependencies\n",
    "\n",
    "* Installation is performed using CERR's [***model installer***]( https://github.com/cerr/model_installer).  \n",
    "\n",
    "* A Conda archive containing dependencies is downloaded to the `conda-pack`   \n",
    "  sub-directory of a configurable `scriptInstallDir`.  \n",
    "  By default `condaEnvPath = '/content/MRI_Pancreas_Fullshot_AnatomicCtxShape/conda-pack'`\n",
    "  \n",
    "* The inference script is located at   \n",
    "  `scriptInstallDir = os.path.join(condaEnvPath,'model_wrapper', run_inference_first_to_last_nii.py')`\n",
    "  \n",
    "  \n",
    "## Running the model\n",
    "\n",
    "```python\n",
    "!python {wrapperPath} {input_nii_directory} {output_nii_directory}\n",
    "```\n",
    "* Data transformations including converting between DICOM and NIfTI formats,  automatic extraction of patient outline, and resizing, are performed using [***pyCERR***](https://github.com/cerr/pyCERR) [2].\n",
    "\n",
    "## References\n",
    "\n",
    "1. Jiang, J., Hong, J., Tringale, K., Reyngold, M., Crane, C., Tyagi, N., & Veeraraghavan, H. (2023). Progressively refined deep joint registration segmentation (ProRSeg) of gastrointestinal organs at risk: Application to MRI and cone-beam CT. Medical Physics, 50(8), 4758-4774.\n",
    "\n",
    "2. Iyer, A., Locastro, E., Apte, A. P., Veeraraghavan, H., & Deasy, J. O. (2021). Portable framework to deploy deep learning segmentation models for medical images. bioRxiv, 2021-03.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GVYj7k5e97G"
   },
   "source": [
    "## License\n",
    "\n",
    "By downloading the software you are agreeing to the following terms and conditions as well as to the Terms of Use of CERR software.\n",
    "\n",
    "**`THE SOFTWARE IS PROVIDED \"AS IS\" AND CERR DEVELOPMENT TEAM AND ITS COLLABORATORS DO NOT MAKE ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, NOR DO THEY ASSUME ANY LIABILITY OR RESPONSIBILITY FOR THE USE OF THIS SOFTWARE.`**\n",
    "\n",
    "`This software is for research purposes only and has not been approved for clinical use.`\n",
    "\n",
    "`Software has not been reviewed or approved by the Food and Drug Administration, and is for non-clinical, IRB-approved Research Use Only. In no event shall data or images generated through the use of the Software be used in the provision of patient care.`\n",
    "  \n",
    "`YOU MAY NOT DISTRIBUTE COPIES of this software, or copies of software derived from this software, to others outside your organization without specific prior written permission from the CERR development team except where noted for specific software products.`\n",
    "\n",
    "`All Technology and technical data delivered under this Agreement are subject to US export control laws and may be subject to export or import regulations in other countries. You agree to comply strictly with all such laws and regulations and acknowledge that you have the responsibility to obtain\n",
    "such licenses to export, re-export, or import as may be required after delivery to you.`\n",
    "\n",
    "**`You may publish papers and books using results produced using software provided that you reference the following`**:\n",
    "  \n",
    "  1. **AI model** :  https://doi.org/10.1002/mp.16527\n",
    "  2. **Data processing** :  https://doi.org/10.1101/2021.03.17.435903\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mP6FHznIg7Yd"
   },
   "source": [
    "\n",
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSvE1KsTj9do"
   },
   "source": [
    "Define paths to input DICOM directory, desired output directory, and a session directory to store temporary files during model execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHbUWoUEj1A2"
   },
   "outputs": [],
   "source": [
    "#I/O paths\n",
    "inputDicomPath = 'your/path/here'\n",
    "workDir = '/content/demo'\n",
    "inputSubDirs = ['Masks']\n",
    "outputDicomPath = os.path.join(workDir, 'AIoutput')\n",
    "sessionPath = os.path.join(workDir, 'temp')\n",
    "\n",
    "if not os.path.exists(workDir):\n",
    "  os.mkdir(outputDicomPath)\n",
    "\n",
    "if not os.path.exists(outputDicomPath):\n",
    "  os.mkdir(outputDicomPath)\n",
    "\n",
    "if not os.path.exists(sessionPath):\n",
    "  os.mkdir(sessionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfduFdNhndfs"
   },
   "source": [
    "## Download pre-trained model, [inference script](https://github.com/cerr/MRI_Pancreas_Fullshot_AnatomicCtxShape), and dependencies to ***scriptInstallDir***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6oEXZbqrqo_"
   },
   "outputs": [],
   "source": [
    "os.chdir(workDir)\n",
    "!git clone https://github.com/cerr/model_installer.git\n",
    "os.chdir(os.path.join(workDir,'model_installer'))\n",
    "\n",
    "modelOpt = '5'  # MRI_Pancreas_Fullshot_AnatomicCtxShape\n",
    "pythonOpt = 'C' # Download packaged Conda environment\n",
    "\n",
    "! source ./installer.sh -m {modelOpt} -d {workDir} -p {pythonOpt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WP3FgsRr2cP"
   },
   "outputs": [],
   "source": [
    "# Location of inference script\n",
    "scriptInstallDir = os.path.join(workDir, 'model_installer', 'MRI_Pancreas_Fullshot_AnatomicCtxShape')\n",
    "scriptPath = os.path.join(scriptInstallDir,\n",
    "                         'model_wrapper',\n",
    "                         'run_inference_first_to_last_nii.py')\n",
    "\n",
    "# Location of activation script for Conda environment\n",
    "activateScript = os.path.join(scriptInstallDir,'bin','activate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsKXYI-dsgcK"
   },
   "source": [
    "## Install ***pyCERR***\n",
    "\n",
    "pyCERR is used for data import/export and pre- and post-processing transformations needed for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRGzE5J7sgcL"
   },
   "outputs": [],
   "source": [
    "!pip install \"pyCERR @ git+https://github.com/cerr/pyCERR.git@testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfcIIiLQsgcM"
   },
   "source": [
    "# Data processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m955pAJsgcN"
   },
   "source": [
    "## Pre-processing  \n",
    "\n",
    "### `processInputData`: Crop scan and input mask around patient outline and resize to 128 x 192 x 128 voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtPOzqWQsgcP"
   },
   "outputs": [],
   "source": [
    "# Map output labels to structure names\n",
    "structToLabelMap  = {\"Liver\": 1,\n",
    "                     \"Bowel_Lg\": 2,\n",
    "                     \"Bowel_Sm\": 3,\n",
    "                     \"Duostomach\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAXBqkTasgcN"
   },
   "outputs": [],
   "source": [
    "import cerr.plan_container as pc\n",
    "from cerr.dataclasses import scan as cerrScn\n",
    "from cerr.dataclasses import structure as cerrStr\n",
    "from cerr.contour import rasterseg as rs\n",
    "from cerr.utils import mask\n",
    "from cerr.utils.image_proc import resizeScanAndMask\n",
    "\n",
    "\n",
    "def processInputData(scanIdx, outlineStructName, structToLabelMap, planC):\n",
    "    \"\"\"Pre-process scan and mask for input to model\"\"\"\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    #          Extract input label map\n",
    "    #---------------------------------------------------\n",
    "    structList = [str.structureName for str in planC.structure]\n",
    "\n",
    "    if structToLabelMap is not None:\n",
    "\n",
    "        segStructList = list(structToLabelMap.keys())\n",
    "        labels = list(structToLabelMap.values())\n",
    "        structNumV = np.zeros(len(labels),dtype=int)\n",
    "\n",
    "        for numLabel in range(len(labels)):\n",
    "            # Get structure indices in planC\n",
    "            structName = segStructList[numLabel]\n",
    "            matchIdxV = cerrStr.getMatchingIndex(structName,\n",
    "                                                 structList,\n",
    "                                                 matchCriteria='exact')\n",
    "            # Ensure association with input scan\n",
    "            assocScansV = [int(cerrScn.getScanNumFromUID(planC.structure[idx].assocScanUID, planC))\n",
    "                           for idx in matchIdxV]\n",
    "            try:\n",
    "                validMatchIdx = matchIdxV[assocScansV.index(scanIdx)]\n",
    "            except:\n",
    "              raise ValueError(\"Missing structure \", structName)\n",
    "            structNumV[numLabel] = validMatchIdx\n",
    "\n",
    "        # Extract label map\n",
    "        maskList = cerrStr.getMaskList(structNumV,\n",
    "                                      planC,\n",
    "                                      labelDict=structToLabelMap)\n",
    "        mask4M = np.array(maskList)\n",
    "        mask4M = np.moveaxis(mask4M, 0, -1)# nRows x nCols x nSlc x nlabels\n",
    "    else:\n",
    "        mask4M = None\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    #          Process input scan\n",
    "    #---------------------------------------------------\n",
    "    modality = 'MR'\n",
    "    scan3M = planC.scan[scanIdx].getScanArray()\n",
    "    scanSizeV = np.shape(scan3M)\n",
    "\n",
    "    # 1. Crop to  patient outline\n",
    "\n",
    "    ## Extract outline\n",
    "    outlineIdx = structList.index(outlineStructName) \\\n",
    "                if outlineStructName in structList else None\n",
    "\n",
    "    if outlineIdx is None:\n",
    "        # Generate outline mask\n",
    "        threshold = 0.03\n",
    "        outline3M = mask.getPatientOutline(scan3M,\n",
    "                                           threshold,\n",
    "                                           normFlag=True)\n",
    "\n",
    "        planC = pc.importStructureMask(outline3M,\n",
    "                                       scanIdx,\n",
    "                                       outlineStructName,\n",
    "                                       planC,\n",
    "                                       None)\n",
    "    else:\n",
    "        # Load outline mask\n",
    "        outline3M = rs.getStrMask(outlineIdx, planC)\n",
    "\n",
    "    ## Crop scan and mask to pt outline\n",
    "    cropMask4M = None\n",
    "    minr, maxr, minc, maxc, mins, maxs, _ = mask.computeBoundingBox(outline3M)\n",
    "    cropScan3M = scan3M[minr:maxr+1, minc:maxc+1, mins:maxs+1]\n",
    "    cropScanSizeV = np.shape(cropScan3M)\n",
    "    if mask4M is not None:\n",
    "        cropMask4M = mask4M[minr:maxr+1, minc:maxc+1, mins:maxs+1, :]\n",
    "\n",
    "    ## Calc. cropped scan grid\n",
    "    gridS = planC.scan[scanIdx].getScanXYZVals()\n",
    "    cropGridS = (gridS[0][minc:maxc+1],\n",
    "                 gridS[1][minr:maxr+1],\n",
    "                 gridS[2][mins:maxs+1])\n",
    "\n",
    "    # 2. Resize scan\n",
    "    ## Crop scan in-plane\n",
    "    outputImgSizeV = [128, 192, cropScanSizeV[2]]\n",
    "    method = 'bicubic'\n",
    "    procScan3M, procMask4M, resizeGridS = resizeScanAndMask(cropScan3M,\n",
    "                                          cropMask4M,\n",
    "                                          cropGridS,\n",
    "                                          outputImgSizeV,\n",
    "                                          method)\n",
    "    ## Pad scan along slices\n",
    "    resizeScanShape = procScan3M.shape\n",
    "    outputImgSizeV = [resizeScanShape[0], resizeScanShape[1], 128]\n",
    "    method = 'padslices'\n",
    "    procPadScan3M, procPadMask4M, padGridS = resizeScanAndMask(procScan3M, \\\n",
    "                                                               procMask4M,\\\n",
    "                                                               resizeGridS, \\\n",
    "                                                               outputImgSizeV,\\\n",
    "                                                               method)\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    #    Import processed scan & mask to planC\n",
    "    #---------------------------------------------------\n",
    "    ## Import scan\n",
    "    planC = pc.importScanArray(procPadScan3M,\n",
    "                                 padGridS[0],\n",
    "                                 padGridS[1],\n",
    "                                 padGridS[2],\n",
    "                                 modality,\n",
    "                                 scanIdx,\n",
    "                                 planC)\n",
    "    processedScanIdx = len(planC.scan) - 1\n",
    "\n",
    "    ## Import mask\n",
    "    processedStrIdxV = []\n",
    "    if procPadMask4M is not None:\n",
    "        for structIndex in range(len(segStructList)):\n",
    "            structName = segStructList[structIndex]\n",
    "            procPadMask3M = procPadMask4M[:, :, :, structIndex]\n",
    "            planC = pc.importStructureMask(procPadMask3M,\n",
    "                                           processedScanIdx,\n",
    "                                           structName,\n",
    "                                           planC,\n",
    "                                           None)\n",
    "            processedStrIdxV.append(len(planC.structure) - 1 )\n",
    "    else:\n",
    "        processedStrIdxV = None\n",
    "\n",
    "    return processedScanIdx, processedStrIdxV, padGridS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1KHjP1LsgcO"
   },
   "source": [
    "\n",
    "## **Post-processing**\n",
    "\n",
    "### `postProcAndImportSeg`: Read label maps, undo pre-processing transformations, and retain only the largest connected component of the resulting mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_GjRVWtsgcP"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def postProcAndImportSeg(modOutputPath, baseScanIdx, outlineStructName,\n",
    "                         structToLabelMap, inputGridS, planC):\n",
    "    \"\"\" Import auto-segmentations to planC\"\"\"\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    #              Read AI-generated mask\n",
    "    #---------------------------------------------------\n",
    "    niiGlob = glob.glob(os.path.join(modOutputPath, '*.nii.gz'))\n",
    "    print('Importing ' + niiGlob[0] + '...')\n",
    "    outputMask = sitk.ReadImage(niiGlob[0])\n",
    "    outputMask3M = sitk.GetArrayFromImage(outputMask)\n",
    "    numStrOrig = len(planC.structure)\n",
    "    numAIStrs = len(structToLabelMap)\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    #      Undo pre-processing transformations\n",
    "    #---------------------------------------------------\n",
    "    ## Extract extents of patient outline\n",
    "    structList = [struct.structureName for struct in planC.structure]\n",
    "    outlineIdx = structList.index(outlineStructName)\n",
    "    outline3M = rs.getStrMask(outlineIdx, planC)\n",
    "    minr, maxr, minc, maxc, mins, maxs, _ = mask.computeBoundingBox(outline3M)\n",
    "\n",
    "    nSlc = maxs-mins+1\n",
    "    resizedDimsV = [128, 192, nSlc]\n",
    "\n",
    "    ## Undo padding\n",
    "    outputScan3M = None\n",
    "    method = 'unpadslices'\n",
    "    _, unPadMask4M, unPadGridS = resizeScanAndMask(outputScan3M,\n",
    "                                                   outputMask3M,\n",
    "                                                   inputGridS,\n",
    "                                                   resizedDimsV,\n",
    "                                                   method)\n",
    "    ## Undo resizing\n",
    "    outputImgSizeV = [maxr-minr+1, maxc-minc+1, nSlc]\n",
    "    method = 'bicubic'\n",
    "    _, resizeMask4M, resizeGridS = resizeScanAndMask(outputScan3M,\n",
    "                                                     unPadMask4M,\n",
    "                                                     unPadGridS,\n",
    "                                                     outputImgSizeV,\n",
    "                                                     method)\n",
    "\n",
    "    ## Undo cropping\n",
    "    baseImgSizeV = list(planC.scan[baseScanIdx].getScanSize())\n",
    "    fullMask4M = np.zeros(baseImgSizeV + [numAIStrs])\n",
    "    fullMask4M[minr:maxr+1, minc:maxc+1, mins:maxs+1, :] = resizeMask4M\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    #             Import results to planC\n",
    "    #---------------------------------------------------\n",
    "    numComponents = 1\n",
    "    structNames = list(structToLabelMap.keys())\n",
    "    for numLabel in range(numAIStrs):\n",
    "        binMask = fullMask4M[:, :, :, numLabel]\n",
    "\n",
    "        structName = 'AI_' + structNames[numLabel]\n",
    "        planC = cerrStr.importStructureMask(binMask,\n",
    "                                            baseScanIdx,\n",
    "                                            structName,\n",
    "                                            planC,\n",
    "                                            None)\n",
    "        # Post-process and replace input structure in planC\n",
    "        structNumV = len(planC.structure) - 1\n",
    "        importMask3M, planC = cerrStr.getLargestConnComps(structNumV,\n",
    "                                                          numComponents,\n",
    "                                                          planC,\n",
    "                                                          saveFlag=True,\n",
    "                                                          replaceFlag=True,\n",
    "                                                          procSructName=structName)\n",
    "\n",
    "    return planC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj7t-J4isgcQ"
   },
   "source": [
    "# Segment OARs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XVVLPjBkYI0"
   },
   "source": [
    "## Apply AI model  to all longitudinal MR datasets  \n",
    "\n",
    "### located in ***inputDicomPath*** and store auto-segmentation results to ***outputDicomPath***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUa9dKRz2Dum"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from cerr import plan_container as pc\n",
    "from cerr.dataclasses import scan as cerrScn\n",
    "from cerr.dcm_export import rtstruct_iod\n",
    "from cerr.utils.ai_pipeline import createSessionDir, getScanNumFromIdentifier\n",
    "\n",
    "fileList = os.listdir(inputDicomPath)\n",
    "numFiles = len(fileList)\n",
    "scanNum = 0\n",
    "modality = 'MR'\n",
    "outlineStructName = 'patient_outline'\n",
    "\n",
    "# Loop over pyCERR files\n",
    "for iFile in range(numFiles):\n",
    "\n",
    "    # Create session dir to store temporary data\n",
    "    modInputPath, modOutputPath = createSessionDir(sessionPath,\n",
    "                                                   inputDicomPath,\n",
    "                                                   inputSubDirs)\n",
    "\n",
    "    # Import DICOM scan to planC\n",
    "    inputFile = fileList[iFile]\n",
    "    dcmDir = os.path.join(inputDicomPath, inputFile)\n",
    "    planC = pc.loadDcmDir(dcmDir)\n",
    "    numExistingStructs = len(planC.structure)\n",
    "    #--------------------\n",
    "    # Pre-process data\n",
    "    #---------------------\n",
    "\n",
    "    #1. Base scan\n",
    "    identifier = {\"seriesDate\": \"last\"}\n",
    "    baseScanIdx = int(getScanNumFromIdentifier(identifier, planC)[0])\n",
    "    exportBaseLabelMap = None\n",
    "    procBaseScanIdx, __, procBaseGridS = processInputData(baseScanIdx,\n",
    "                                                          outlineStructName,\n",
    "                                                          exportBaseLabelMap,\n",
    "                                                          planC)\n",
    "\n",
    "    #2. Moving scan\n",
    "    identifier = {\"seriesDate\": \"first\"}\n",
    "    movScanIdx = int(getScanNumFromIdentifier(identifier, planC)[0])\n",
    "    exportMovLabelMap = structToLabelMap\n",
    "    procMovScanIdx, procMovStrIdxV, procMovGridS = \\\n",
    "                                    processInputData(movScanIdx,\n",
    "                                                     outlineStructName,\n",
    "                                                     exportMovLabelMap,\n",
    "                                                     planC)\n",
    "\n",
    "    # Export processed inputs to NIfTI\n",
    "    baseScanFile = os.path.join(modInputPath,\n",
    "                            f\"{inputFile}_MR SCAN_last_scan_3D.nii.gz\")\n",
    "    movScanFile = os.path.join(modInputPath,\n",
    "                           f\"{inputFile}_MR SCAN_first_scan_3D.nii.gz\")\n",
    "    movMaskFile = os.path.join(modInputPath, inputSubDirs[0], \\\n",
    "                           f\"{inputFile}_MR SCAN_first_4D.nii.gz\")\n",
    "    planC.scan[procBaseScanIdx].saveNii(baseScanFile)\n",
    "    planC.scan[procMovScanIdx].saveNii(movScanFile)\n",
    "    pc.saveNiiStructure(movMaskFile,\n",
    "                        exportMovLabelMap,\n",
    "                        planC,\n",
    "                        strNumV=procMovStrIdxV,\n",
    "                        dim=4)\n",
    "\n",
    "    # Apply pretrained AI model\n",
    "    subprocess.run(f\"source {activateScript} && python {scriptPath} \\\n",
    "                  {modInputPath} {modOutputPath}\", \\\n",
    "                  capture_output=False,shell=True,executable=\"/bin/bash\")\n",
    "\n",
    "\n",
    "    #Import segmentations to planC\n",
    "    planC = postProcAndImportSeg(modOutputPath,\n",
    "                                 baseScanIdx,\n",
    "                                 outlineStructName,\n",
    "                                 structToLabelMap,\n",
    "                                 procMovGridS,\n",
    "                                 planC)\n",
    "\n",
    "    newNumStructs = len(planC.structure)\n",
    "\n",
    "\n",
    "    # Export segmentations to DICOM\n",
    "    structFileName = fileList[iFile] + '_AI_seg.dcm'\n",
    "    structFilePath = os.path.join(outputDicomPath, structFileName)\n",
    "    structNumV = np.arange(numExistingStructs+1, newNumStructs)\n",
    "    indOrigV = np.array([cerrScn.getScanNumFromUID(\\\n",
    "                         planC.structure[structNum].assocScanUID, planC)\\\n",
    "                         for structNum in structNumV], dtype=int)\n",
    "    structsToExportV = structNumV[indOrigV == baseScanIdx]\n",
    "    seriesDescription = \"AI Generated\"\n",
    "    exportOpts = {'seriesDescription': seriesDescription}\n",
    "    rtstruct_iod.create(structsToExportV,\n",
    "                        structFilePath,\n",
    "                        planC,\n",
    "                        exportOpts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLzFp-l_sgcT"
   },
   "source": [
    "# Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8FTwNqhsgcT"
   },
   "source": [
    "## Overlay AI segmentations on scan for visualization using ***Matplotlib***\n",
    "\n",
    "Note: This example displays the last segmented dataset by default.  \n",
    "Load the appropriate pyCERR archive to `planC` to view results for desired dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWQD1KeVsgcT"
   },
   "outputs": [],
   "source": [
    "from cerr.viewer import showMplNb\n",
    "\n",
    "dispStructsV = list(structsToExportV[1:])\n",
    "\n",
    "showMplNb(planC=planC, scanNum=baseScanIdx,\n",
    "          structNums=dispStructsV,\n",
    "          windowCenter=41100, windowWidth=80300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
